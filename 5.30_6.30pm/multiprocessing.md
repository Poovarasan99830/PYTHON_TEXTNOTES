
# `multiprocessing`


2ï¸âƒ£ `multiprocessing` (For CPU-bound tasks, fully utilizes multiple cores)**
     - Uses **multiple processes**, each with **its own memory space**.
     - **Bypasses the GIL**, allowing true **parallel execution** across CPU cores.
     - Best for **CPU-heavy computations** (ML, image processing, data processing).
     - More memory overhead since each process **has its own copy of Python objects**.




## ğŸ”¹ Real-time Example with Code

```python
from multiprocessing import Process
import time, os

def work(n):
    print(f"Process {os.getpid()} working on {n}")
    time.sleep(2)
    print(f"Done {n}")

if __name__ == "__main__":
    tasks = [Process(target=work, args=(i,)) for i in range(5)]
    for t in tasks: t.start()
    for t in tasks: t.join()
    print("All done!")

# ___________________________________________________

âœ… Each task runs in **parallel** â†’ reduces total time.


## ğŸ”¹ Tasks

1. Write a program to calculate factorials of 5 numbers in parallel.
2. Use `multiprocessing.Queue` to send results back to main process.
3. Use `Pool.map()` to apply a function on a list of 100 items.

---

## ğŸ”¹ Task Explanation

| Task      | Explanation                                |
| --------- | ------------------------------------------ |
| Factorial | Each process calculates independently.     |
| Queue     | Inter-process communication (IPC).         |
| Pool Map  | Easy distribution of workload across CPUs. |

---

## ğŸ”¹ Where Used

* Data science: matrix multiplications, simulations.
* AI/ML: parallel model training.
* Image/video/audio processing.
* Large file parsing.

---

## ğŸ”¹ Levels

* **Beginner** â†’ Process, start(), join().
* **Intermediate** â†’ Pool, Queue, Pipe.
* **Advanced** â†’ Shared memory, synchronization (Locks, Semaphores).
* **General** â†’ Heavy CPU tasks.

---

## ğŸ”¹ Best Practices

* Use `if __name__ == "__main__":` (Windows requirement).
* Avoid **too many processes** â†’ overhead increases.
* Use `Pool` for many small tasks.
* Prefer `concurrent.futures.ProcessPoolExecutor` for cleaner syntax.

---

## ğŸ”¹ Pitfalls

* Higher memory usage (each process separate).
* Communication between processes is slower than threads.
* Debugging across processes is harder.

---

## ğŸ”¹ Interview Questions

1. Difference between multiprocessing and threading?
2. How does Python overcome GIL using multiprocessing?
3. When to use Pool vs Process?
4. Explain Queue vs Pipe.

---

---____________________________________________________________________________________________________

# ğŸ”¹ **Asynchronous Programming in Python (360Â° View)**

---

## âœ… Definition

* Async = **concurrent execution**, not parallel.
* Uses **event loop** to schedule tasks.
* Best for **I/O-bound tasks** (waiting for DB, API, network).

---

## ğŸ”¹ Real-time Example with Code

```python
import asyncio

async def task(n):
    print(f"Start {n}")
    await asyncio.sleep(2)
    print(f"End {n}")

async def main():
    await asyncio.gather(*(task(i) for i in range(3)))

asyncio.run(main())
```

âœ… Tasks run **concurrently** â†’ total time = ~2s instead of 6s.

---

## ğŸ”¹ Tasks

1. Write an async program to simulate 3 file downloads.
2. Use `asyncio.create_task()` to schedule tasks.
3. Fetch multiple URLs using `aiohttp`.

---

## ğŸ”¹ Task Explanation

| Task          | Explanation                     |
| ------------- | ------------------------------- |
| File download | No waiting â†’ overlap execution. |
| create_task   | Fire-and-forget scheduling.     |
| aiohttp       | Real-world async networking.    |

---

## ğŸ”¹ Where Used

* Web servers (FastAPI, aiohttp).
* Chat applications.
* Stock market live updates.
* Gaming servers.
* Real-time notifications.

---

## ğŸ”¹ Levels

* **Beginner** â†’ async def, await, coroutines.
* **Intermediate** â†’ asyncio.gather, asyncio.create_task.
* **Advanced** â†’ aiohttp, async DB drivers, producer-consumer patterns.
* **General** â†’ I/O tasks.

---

## ğŸ”¹ Best Practices

* Always use `asyncio.gather` for parallel async tasks.
* Avoid blocking code (`time.sleep`) inside async â†’ use `await asyncio.sleep()`.
* Use `async with` for resources like DB connections.
* Mix async + multiprocessing for combined I/O + CPU tasks.

---

## ğŸ”¹ Pitfalls

* Not true parallelism (still single thread).
* Mixing blocking code breaks async flow.
* Debugging async stack traces is tricky.

---

## ğŸ”¹ Interview Questions

1. Difference between async and threading?
2. How does event loop work?
3. Can async overcome GIL? (No, only multiprocessing can).
4. When to use `asyncio.create_task` vs `await`?

---

---

# ğŸ”¹ **Multiprocessing vs Asynchronous â€” Side by Side**

| Feature        | Multiprocessing                      | Asynchronous                |
| -------------- | ------------------------------------ | --------------------------- |
| Nature         | Parallel execution                   | Concurrent execution        |
| Best for       | CPU-bound tasks                      | I/O-bound tasks             |
| Memory         | Each process has separate memory     | Shared single memory/thread |
| Overcomes GIL? | âœ… Yes                                | âŒ No                        |
| Example        | Image processing, ML training        | API calls, DB queries       |
| Tool           | multiprocessing, ProcessPoolExecutor | asyncio, aiohttp, FastAPI   |
| Overhead       | Heavy (process creation)             | Light (event loop)          |

---

# ğŸ”¹ General Real-life Applications

âœ… **Multiprocessing**

* Data crunching in AI/ML
* Video rendering
* Big simulations (climate models, physics)

âœ… **Async**

* Web APIs (FastAPI)
* Messaging apps (WhatsApp, Slack)
* IoT sensors streaming
* Live dashboards

---

âš¡ **360Â° Summary**

* **Multiprocessing** â†’ heavy CPU work, true parallelism, more memory.
* **Async** â†’ lightweight, single-thread concurrency, perfect for I/O waits.
* Often combined in **real-world projects**: e.g., Web API server (async) + background ML model processing (multiprocessing).






#  ___________________________________________________________
#  ğŸŸ¢ Case 1: without multi processing

# import os, time

# def work(n):
#     print(f"Process {os.getpid()} working on {n}", flush=True)
#     time.sleep(2)
#     print(f"Done {n}", flush=True)

# for i in range(3):   # direct function call
#     work(i)



# ğŸ‘‰ All tasks same PID (12345) â†’ because everything runs in main process only.
# ğŸ‘‰ Tasks run one by one (sequential).

# ___________________________________________________________


# ğŸŸ¢ Case 2: With Multiprocessing



# from multiprocessing import Process
# import os, time

# def work(n):
#     print(f"Process {os.getpid()} working on {n}", flush=True)
#     time.sleep(2)
#     print(f"Done {n}", flush=True)

# if __name__ == "__main__":
#     tasks = [Process(target=work, args=(i,)) for i in range(5)]
#     for t in tasks: 
#         t.start()
#     for t in tasks: 
#         t.join()



# ğŸ‘‰ Different PIDs â†’ each task runs in a separate child process.
# ğŸ‘‰ Tasks run parallel (simultaneous) â†’ all â€œworking on â€¦â€ print first, then after ~2 seconds all â€œDone â€¦â€ appear.


# ___________________________________________________________________


# | Feature          | Without Multiprocessing | With Multiprocessing        |
# | ---------------- | ----------------------- | --------------------------- |
# | **Process ID**   | Same for all (main PID) | Different PID for each task |
# | **Execution**    | Sequential (one by one) | Parallel (simultaneous)     |
# | **Speed**        | Slower (waits for each) | Faster (tasks overlap)      |
# | **Output order** | Predictable             | Mixed / interleaved         |


# ____________________________________________________________


## ğŸŸ¢ Python Demo: Timing Comparison

```python
import threading, time, os

# ---------------------------
# Case 1: Without Multithreading
# ---------------------------
def work(n):
    print(f"Process {os.getpid()} working on {n}", flush=True)
    time.sleep(2)
    print(f"Done {n}", flush=True)

print("=== Without Multithreading ===")
start = time.time()

for i in range(3):
    work(i)

end = time.time()
print(f"Total time (no threading): {end - start:.2f} seconds\n")

# ---------------------------
# Case 2: With Multithreading
# ---------------------------
def work_thread(n):
    print(f"Thread {threading.get_ident()} in PID {os.getpid()} working on {n}", flush=True)
    time.sleep(2)
    print(f"Done {n}", flush=True)

print("=== With Multithreading ===")
start = time.time()

threads = [threading.Thread(target=work_thread, args=(i,)) for i in range(3)]
for t in threads:
    t.start()
for t in threads:
    t.join()

end = time.time()
print(f"Total time (with threading): {end - start:.2f} seconds")
```

---

## ğŸ”¹ Expected Output

```
=== Without Multithreading ===
Process 12345 working on 0
Done 0
Process 12345 working on 1
Done 1
Process 12345 working on 2
Done 2
Total time (no threading): 6.00 seconds

=== With Multithreading ===
Thread 45678 in PID 12345 working on 0
Thread 45679 in PID 12345 working on 1
Thread 45680 in PID 12345 working on 2
Done 0
Done 2
Done 1
Total time (with threading): 2.01 seconds
```

---

### ğŸ”¹ Explanation (Thunglish)

1. **Without threading** â†’ tasks run **one by one** â†’ 3 tasks Ã— 2 sec each = ~6 sec total.
2. **With threading** â†’ tasks run **concurrently** â†’ all sleep(2) happens at the same time â†’ total ~2 sec.
3. **Output order** â†’ With threading, `Done` lines **may shuffle** because threads finish at slightly different times.
4. **PID** â†’ Same for all, **Thread ID** â†’ different for each thread.

---

ğŸ’¡ **Conclusion:**

* **Threading** helps **I/O-bound tasks** finish much faster.
* CPU-bound tasks wonâ€™t see much speedup in Python because of **GIL**, but I/O tasks benefit big time.

---

# _______________________________________________________________


## ğŸŸ¢ Case 3: With Multithreading

```python
import threading, os, time

def work(n):
    print(f"Thread {threading.get_ident()} working on {n}", flush=True)
    time.sleep(2)
    print(f"Done {n}", flush=True)

threads = [threading.Thread(target=work, args=(i,)) for i in range(5)]
for t in threads:
    t.start()
for t in threads:
    t.join()
```

### ğŸ‘‰ Behavior

* **Thread ID** is different for each thread (not PID).
* Runs **concurrently** (all â€œworking on â€¦â€ prints appear quickly).
* But in **CPython**, because of the **GIL (Global Interpreter Lock)**, only one thread executes Python bytecode at a time.
* Still useful for **I/O-bound tasks** (e.g., waiting, network requests).
* Output order = **not guaranteed** (like multiprocessing).

---

## ğŸŸ¢ Case 4: With AsyncIO (Asynchronous Programming)

```python
import asyncio, os

async def work(n):
    print(f"Task {n} running in PID {os.getpid()}", flush=True)
    await asyncio.sleep(2)
    print(f"Done {n}", flush=True)

async def main():
    tasks = [asyncio.create_task(work(i)) for i in range(5)]
    await asyncio.gather(*tasks)

asyncio.run(main())
```

### ğŸ‘‰ Behavior

* All tasks run in **the same process and same thread**.
* `asyncio` switches between tasks **during waiting (await)**.
* Very efficient for **I/O-bound tasks** (network calls, file ops, DB queries).
* Output order = **not guaranteed**, depends on scheduling, but usually all "working on" first, then all "Done".
* Fastest for many I/O operations since no process/thread overhead.

---

## ğŸŸ¢ Final Comparison Table

| Feature            | Without Multiprocessing | With Multiprocessing          | With Multithreading             | With AsyncIO                |
| ------------------ | ----------------------- | ----------------------------- | ------------------------------- | --------------------------- |
| **Process/Thread** | Same PID (main process) | Different PID for each task   | Same PID, diff Thread IDs       | Same PID, same Thread       |
| **Execution**      | Sequential (blocking)   | Parallel (true multi-core)    | Concurrent (GIL limits CPU)     | Cooperative concurrency     |
| **Best For**       | Very small tasks        | CPU-bound (heavy compute)     | I/O-bound (network, disk, etc.) | Massive I/O-bound tasks     |
| **Speed**          | Slow (one by one)       | Fast (tasks overlap on cores) | Medium (context switches)       | Fastest for I/O-bound tasks |
| **Output order**   | Predictable             | Mixed / interleaved           | Mixed / interleaved             | Mixed / interleaved         |

---

âœ… **Thunglish summary:**

* **Without Multiprocessing** â†’ à®à®²à¯à®²à®¾à®®à¯‡ main process-à®² sequential.
* **Multiprocessing** â†’ à®’à®µà¯à®µà¯Šà®°à¯ task-à®•à¯à®•à¯à®®à¯ à®¤à®©à®¿ process, true parallelism (CPU-boundà®•à¯à®•à¯ best).
* **Multithreading** â†’ à®à®²à¯à®²à®¾à®®à¯ same process-à®², different threads. GIL à®•à®¾à®°à®£à®®à®¾ CPU tasks slow, à®†à®©à®¾ I/O tasks super.
* **AsyncIO** â†’ à®’à®°à¯‡ thread-à®² cooperative switching, thousands of I/O tasks handle à®ªà®£à¯à®£ à®®à¯à®Ÿà®¿à®¯à¯à®®à¯.

